{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer\n",
    "Como se mencionó en el trabajo anterior, es preferible usar la métrica recall, puesto que minimiza el número de tumores maligos predichos, por lo que es menos probable que catalogue un tumor maligno como benigno y ponga la vida de alguien en riesgo por falta de detección.\n",
    "\n",
    "Se tomará la base de datos preprocesada del trabajo anterior.\n",
    "\n",
    "El código para obtener los modelos es el siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BreastCancer.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filterwarnings\n\u001b[0;32m      4\u001b[0m filterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBreastCancer.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m load(f)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreastCancerModels.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\Apps\\Desktop\\Parcial\\.conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BreastCancer.pkl'"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "with open( 'BreastCancer.pkl', 'rb' ) as f:\n",
    "    X_train, X_test, y_train, y_test = load(f)\n",
    "\n",
    "with open( 'BreastCancerModels.pkl', 'rb' ) as f:\n",
    "    Models = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>Best C</th>\n",
       "      <th>Best gamma</th>\n",
       "      <th>cpu time</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>52.625473</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>4926.816340</td>\n",
       "      <td>0.908046</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.781268</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.883242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.656181</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.813187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kernel     Best C  Best gamma     cpu time  precision    recall  f1_score  \\\n",
       "0   linear      0.100      0.0001    52.625473   0.841584  0.934066  0.885417   \n",
       "1     poly      0.001    100.0000  4926.816340   0.908046  0.868132  0.887640   \n",
       "2      rbf  10000.000      0.0100     2.781268   0.921348  0.901099  0.911111   \n",
       "3  sigmoid   1000.000      0.0001     2.656181   0.841584  0.934066  0.885417   \n",
       "\n",
       "        auc  \n",
       "0  0.813187  \n",
       "1  0.857143  \n",
       "2  0.883242  \n",
       "3  0.813187  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "results = DataFrame(columns=['kernel', 'Best C', 'Best gamma', 'cpu time', 'precision', 'recall', 'f1_score', 'auc'])\n",
    "\n",
    "for Model in Models:\n",
    "    pred = Model['model']\n",
    "    params = pred.best_params_\n",
    "    cpu_time = Model['time']\n",
    "    \n",
    "    y_pred = pred.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    results.loc[ len( results.index ) ] = { 'kernel': Model['kernel'], 'Best C': params['classifier__C'], \n",
    "        'Best gamma': params['classifier__gamma'], 'cpu time': cpu_time, 'precision': precision, \n",
    "        'recall': recall, 'f1_score': f1, 'auc': auc }\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es de considerabe que el kernel *poly* fué aquel que más tiempo consumió, teniendo en cuenta que se realizó en un servidor con 6 cores, y se hizo uso de la librería *scikit-learn-intelex*, que disminuyó considerablemente el tiempo de ejecución para cada modelo. En futuros puntos, se optará por usar *BayesSearchCV*, una extensión de *GridSearchCV* que aplica los principios de la optimización bayesiana. Cabe considerar que la mayoría del tiempo en ejecución del segundo kernel proviene de usar valores altos de gamma y C.\n",
    "\n",
    "Por otro lado, podemos ver que el kernel rbf es un kernel ideal para la clasificación ya que posee muy buenos scores de f1 u auc, lo que indica una buena clasificación para ambas categorías. \n",
    "\n",
    "Código fuente para los modelos (No ejecutar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load, dump\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "\n",
    "from numpy import logspace\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__C': logspace( -4, 4, 9 ),\n",
    "    'classifier__gamma': logspace( -4, 4, 9 )\n",
    "}\n",
    "\n",
    "models = []\n",
    "\n",
    "cv = StratifiedShuffleSplit( n_splits=5, test_size=0.2, random_state=37 )\n",
    "\n",
    "for kernel in kernels:\n",
    "    model = {}\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', SVC( kernel = kernel ))\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV( pipe, param_grid = param_grid, cv = cv, scoring = 'roc_auc', n_jobs=-1, verbose = 2 )\n",
    "    start = time()\n",
    "    gs.fit( X_train, y_train )\n",
    "    end = time()\n",
    "\n",
    "    model['kernel'] = kernel\n",
    "    model['model'] = gs\n",
    "    model['time'] = end - start\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing\n",
    "\n",
    "De igual manera que con el punto anterior, se usará la misma base usada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( 'BostonHousing.pkl', 'rb' ) as f:\n",
    "    X_train, X_test, y_train, y_test = load(f)\n",
    "\n",
    "with open( 'BostonHousingModels.pkl', 'rb' ) as f:\n",
    "    Models = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>Best C</th>\n",
       "      <th>Best gamma</th>\n",
       "      <th>Best epsilon</th>\n",
       "      <th>cpu time</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>992.835901</td>\n",
       "      <td>6.821104</td>\n",
       "      <td>0.552228</td>\n",
       "      <td>23.027216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>231202.881519</td>\n",
       "      <td>8.105061</td>\n",
       "      <td>0.367792</td>\n",
       "      <td>20.460922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.421697</td>\n",
       "      <td>47.737602</td>\n",
       "      <td>4.763599</td>\n",
       "      <td>0.781617</td>\n",
       "      <td>15.762402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.299065</td>\n",
       "      <td>6.821591</td>\n",
       "      <td>0.552164</td>\n",
       "      <td>23.121607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kernel   Best C  Best gamma  Best epsilon       cpu time      RMSE  \\\n",
       "0   linear     0.10      0.0001      1.000000     992.835901  6.821104   \n",
       "1     poly     0.01     10.0000      0.031623  231202.881519  8.105061   \n",
       "2      rbf  1000.00      0.1000      0.421697      47.737602  4.763599   \n",
       "3  sigmoid    10.00      0.0100      1.000000      38.299065  6.821591   \n",
       "\n",
       "         R2       MAPE  \n",
       "0  0.552228  23.027216  \n",
       "1  0.367792  20.460922  \n",
       "2  0.781617  15.762402  \n",
       "3  0.552164  23.121607  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from numpy import mean, sqrt, abs\n",
    "\n",
    "results = DataFrame(columns=['kernel', 'Best C', 'Best gamma', 'Best epsilon','cpu time', 'RMSE', 'R2', 'MAPE'])\n",
    "\n",
    "for Model in Models:\n",
    "    pred = Model['model']\n",
    "    params = pred.best_params_\n",
    "    cpu_time = Model['time']\n",
    "    \n",
    "    y_pred = pred.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = mean(abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "    results.loc[ len( results.index ) ] = { 'kernel': Model['kernel'], 'Best C': params['classifier__C'],\n",
    "        'Best gamma': params['classifier__gamma'], 'Best epsilon': params['classifier__epsilon'], 'cpu time': cpu_time, \n",
    "        'RMSE': rmse, 'R2': r2, 'MAPE': mape }\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de regresión, se comparten ciertas tendencias del caso anterior. En primer lugar, cabe aclarar que la gran diferencia de tiempo entre los dos se puede deber dada la inclusión de una variable adicional `epsilon`, lo que aumenta el espacio de búsqueda. Aún así, es notable que el kernel *poly* tomó un total de más de 60 horas, diferencia comparable con los menos de 20 minutos del kernel lineal, y menos de un minuto para los últimos dos. Así como en el caso anterior, la evaluación se retrasaba con valores de C y gamma superiores a 100. Podemos ver adicionalmente que al igual que el caso previo, el mejor kernel resultó siendo el rbf, en comparación con todos los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy import logspace\n",
    "from time import time\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__C': logspace( -4, 4, 9 ),\n",
    "    'classifier__gamma': logspace( -4, 4, 9 ),\n",
    "    'classifier__epsilon': logspace( -3, 0, 9 )\n",
    "}\n",
    "\n",
    "models = []\n",
    "\n",
    "cv = ShuffleSplit( n_splits=5, test_size=0.2, random_state=37 )\n",
    "\n",
    "for kernel in kernels:\n",
    "    model = {}\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', SVR( kernel = kernel ))\n",
    "    ])\n",
    "\n",
    "    gs = GridSearchCV( pipe, cv = cv, param_grid = param_grid, scoring = 'neg_mean_squared_error', n_jobs=-1, verbose = 2 )\n",
    "    start = time()\n",
    "    gs.fit( X_train, y_train )\n",
    "    end = time()\n",
    "    \n",
    "    model['kernel'] = kernel\n",
    "    model['model'] = gs\n",
    "    model['time'] = end - start\n",
    "    models.append(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}